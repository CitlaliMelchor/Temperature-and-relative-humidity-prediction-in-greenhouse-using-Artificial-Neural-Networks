{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows some information to describe how the last Mean Square Error of the Artificial Neural Networks variates when training several times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pybrain\n",
    "from pybrain.structure import RecurrentNetwork, FeedForwardNetwork, LinearLayer, SigmoidLayer, FullConnection\n",
    "from IPython.display import Image\n",
    "from pybrain.structure import connections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised import BackpropTrainer\n",
    "from pybrain.tools.customxml import NetworkWriter\n",
    "from pybrain.tools.customxml import NetworkReader\n",
    "%pylab inline --no-import-all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Eval_FF**, **Eval_R** and **Eval_R2** functions train a network (Feedforward and Recurrent, respectively) with a *dataset*, in a determinated number of *epochs*, for an a given number of *samples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Eval_FF (net,data,s,t,epochs,samples):\n",
    "    a = np.array([]) ## MSE array\n",
    "            \n",
    "\n",
    "    ##_______________________________________________________________________________________________________\n",
    "    \n",
    "    for n in range (0,samples):  ##Repeat the training 'samples' times\n",
    "        \n",
    "        ##____________________________________create the FF network__________________________________________\n",
    "        netF = NetworkReader.readFrom(net)\n",
    "\n",
    "        \n",
    "        #____________________________________________Training____________________________________________\n",
    "    \n",
    "        trainer = BackpropTrainer(netF, data, learningrate = 0.001, momentum = 0.99, verbose=False)\n",
    "        errors = np.array([])\n",
    "        for epoch in range(0,epochs):\n",
    "            temp = trainer.train()\n",
    "            er2=np.array([])\n",
    "            for inp in s:\n",
    "                j=netF.activate(inp)\n",
    "                er2=np.append(er2,j)\n",
    "            er2=np.reshape(er2,[len(s),2])\n",
    "            errors=np.append(errors,mse(er2,t))\n",
    "            \n",
    "        a= np.append(a,errors[epochs-1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Eval_R (net,data,s,t,epochs,samples):\n",
    "    a = np.array([])\n",
    " \n",
    "    ##_________________________________________________________________________________________________\n",
    "    \n",
    "    for n in range (0,samples):\n",
    "        netR = NetworkReader.readFrom(net)       \n",
    "        #____________________________________________Training____________________________________________\n",
    "    \n",
    "        trainer = BackpropTrainer(netR, data, learningrate = 0.001, momentum = 0.99, verbose=False)\n",
    "        errors = np.array([])\n",
    "        for epoch in range(0,epochs):\n",
    "            netR.reset()\n",
    "            temp = trainer.train()\n",
    "            er2=np.array([])\n",
    "            for inp in s:\n",
    "                j=netF.activate(inp)\n",
    "                er2=np.append(er2,j)\n",
    "            er2=np.reshape(er2,[len(s),2])\n",
    "            errors=np.append(errors,mse(er2,t))\n",
    "            \n",
    "        a= np.append(a,errors[epochs-1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Eval_R2 (net,data,s,t,epochs,samples):\n",
    "    a = np.array([])\n",
    "\n",
    "        \n",
    "    ##________________________________________________________________________________________________\n",
    "    \n",
    "    for n in range (0,samples):\n",
    "        netR = NetworkReader.readFrom(net)\n",
    "\n",
    "        netR.maxoffset=2\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #____________________________________________Training____________________________________________     \n",
    "    \n",
    "        trainer = BackpropTrainer(netR, data, learningrate = 0.001, momentum = 0.99, verbose=False)\n",
    "        errors = np.array([])\n",
    "        for epoch in range(0,epochs):\n",
    "            netR.reset()\n",
    "            temp = trainer.train()\n",
    "            er2=np.array([])\n",
    "            for inp in s:\n",
    "                j=netF.activate(inp)\n",
    "                er2=np.append(er2,j)\n",
    "            er2=np.reshape(er2,[len(s),2])\n",
    "            errors=np.append(errors,mse(er2,t))\n",
    "            \n",
    "        a= np.append(a,errors2[epochs-1])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getcsv( filename ):\n",
    "    temp = np.fromfile( filename, sep=';' )\n",
    "    numcols = len( temp )\n",
    "    del( temp )\n",
    "    df = pd.read_csv( filename, sep=';', names = [ x+1 for x in range(numcols)] )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=getcsv('train.csv')\n",
    "val = getcsv( 'val.csv' )\n",
    "cols = [ \\\n",
    "    'Record(1)', 'Temperature(1)', 'RelHum(1)', \\\n",
    "    'Ventilation(1)', 'Screening(1)', 'Heating(1)', 'Cooling(1)', \\\n",
    "    'LAI(1)', 'OutTemp(1)', 'OutRelHum(1)', 'OutRad(1)', 'OutWindVel(1)', \\\n",
    "    'HourAngle(1)', 'Declination(1)', 'Elevation(1)', 'RadTheor(1)', \\\n",
    "    'Record(0)', 'Temperature(0)', 'RelHum(0)', \\\n",
    "    'Ventilation(0)', 'Screening(0)', 'Heating(0)', 'Cooling(0)', \\\n",
    "    'LAI(0)', 'OutTemp(0)', 'OutRelHum(0)', 'OutRad(0)', 'OutWindVel(0)', \\\n",
    "    'HourAngle(0)', 'Declination(0)', 'Elevation(0)', 'RadTheor(0)', \\\n",
    "    'Record(-1)', 'Temperature(-1)', 'RelHum(-1)', \\\n",
    "    'Ventilation(-1)', 'Screening(-1)', 'Heating(-1)', 'Cooling(-1)', \\\n",
    "    'LAI(-1)', 'OutTemp(-1)', 'OutRelHum(-1)', 'OutRad(-1)', 'OutWindVel(-1)', \\\n",
    "    'HourAngle(-1)', 'Declination(-1)', 'Elevation(-1)', 'RadTheor(-1)', \\\n",
    "    'Record(-2)', 'Temperature(-2)', 'RelHum(-2)', \\\n",
    "    'Ventilation(-2)', 'Screening(-2)', 'Heating(-2)', 'Cooling(-2)', \\\n",
    "    'LAI(-2)', 'OutTemp(-2)', 'OutRelHum(-2)', 'OutRad(-2)', 'OutWindVel(-2)', \\\n",
    "    'HourAngle(-2)', 'Declination(-2)', 'Elevation(-2)', 'RadTheor(-2)', \\\n",
    "    'Record(-3)', 'Temperature(-3)', 'RelHum(-3)', \\\n",
    "    'Ventilation(-3)', 'Screening(-3)', 'Heating(-3)', 'Cooling(-3)', \\\n",
    "    'LAI(-3)', 'OutTemp(-3)', 'OutRelHum(-3)', 'OutRad(-3)', 'OutWindVel(-3)', \\\n",
    "    'HourAngle(-3)', 'Declination(-3)', 'Elevation(-3)', 'RadTheor(-3)', \\\n",
    "    ]\n",
    "train.columns = cols\n",
    "val.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexm=([\"maximos\",\"minimos\"])\n",
    "mm = pd.DataFrame(columns=train.columns,index=indexm)\n",
    "\n",
    "for n in range(1,train.shape[1]):\n",
    "    max1=max(train[train.columns[n]])\n",
    "    max2=max(val[val.columns[n]])\n",
    "    mm[mm.columns[n]][\"maximos\"]=max(max1,max2)\n",
    "    \n",
    "    min1=min(train[train.columns[n]])\n",
    "    min2=min(val[val.columns[n]])\n",
    "    mm[mm.columns[n]][\"minimos\"]=min(min1,min2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(x,maxi,mini):\n",
    "    Vnorm=(2*((x-mini)/(maxi-mini)))-1\n",
    "    return Vnorm  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ntrain = pd.DataFrame(columns=train.columns)\n",
    "for n in range(1,train.shape[1]):\n",
    "    ar=train[train.columns[n]]\n",
    "    Ntrain[Ntrain.columns[n]]=norm(ar,mm[mm.columns[n]][\"maximos\"],mm[mm.columns[n]][\"minimos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=np.array([Ntrain['Temperature(-2)'],Ntrain['RelHum(-2)'],Ntrain['Ventilation(-2)'],Ntrain['Screening(-2)'], \\\n",
    "           Ntrain['HourAngle(-2)'],Ntrain['Declination(-2)'],Ntrain['Elevation(-2)'],Ntrain['RadTheor(-2)'], \\\n",
    "           Ntrain['Temperature(-1)'],Ntrain['RelHum(-1)'],Ntrain['Ventilation(-1)'],Ntrain['Screening(-1)'], \\\n",
    "           Ntrain['HourAngle(-1)'],Ntrain['Declination(-1)'],Ntrain['Elevation(-1)'],Ntrain['RadTheor(-1)'], \\\n",
    "           Ntrain['Temperature(0)'],Ntrain['RelHum(0)'],Ntrain['Ventilation(0)'],Ntrain['Screening(0)'], \\\n",
    "           Ntrain['HourAngle(0)'],Ntrain['Declination(0)'],Ntrain['Elevation(0)'],Ntrain['RadTheor(0)']]).T\n",
    "\n",
    "t=np.array([Ntrain['Temperature(1)'],Ntrain['RelHum(1)']]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sR=np.array([Ntrain['Temperature(0)'],Ntrain['RelHum(0)'],Ntrain['Ventilation(0)'],Ntrain['Screening(0)'], \\\n",
    "           Ntrain['HourAngle(0)'],Ntrain['Declination(0)'],Ntrain['Elevation(0)'],Ntrain['RadTheor(0)']]).T\n",
    "\n",
    "tR=np.array([Ntrain['Temperature(1)'],Ntrain['RelHum(1)']]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a=len(s)\n",
    "a=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataF = SupervisedDataSet(24,2)\n",
    "dataR = SupervisedDataSet(8,2)\n",
    "\n",
    "for m in range(0,a):\n",
    "    dataF.addSample(s[m],t[m])  \n",
    "    dataR.addSample(sR[m],tR[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Number of epochs\n",
    "n=50\n",
    "\n",
    "## Number of Samples\n",
    "m=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F=Eval_FF ('NET_FF.xml',dataF,s,t,n,m) ##For n epochs, training m times\n",
    "R=Eval_R ('NET_R.xml',dataR,sR,tR,n,m) ##For n epochs, training m times\n",
    "R2=Eval_R2 ('NET_R2.xml',dataR,sR,tR,n,m) ##For n epochs, training m times\n",
    "Errors=([F, R, R2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of the data points divided by the number data points\n",
    "$$M=\\frac{\\sum_{i=0}^n (x_i)}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN=np.array([])\n",
    "for n in range(0,len(Errors)):\n",
    "    MEAN=np.append(MEAN,Errors[n].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Standar Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average difference between the data points and their mean:\n",
    "\n",
    "$$SD=\\sqrt{\\sum \\frac{(x-M)^2}{n-1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Sd=np.array([])\n",
    "for n in range(0,len(Errors)):\n",
    "    Sd=np.append(Sd,Errors[n].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, sharex=True, figsize=(10,7))\n",
    "a=len(Errors)\n",
    "ind = np.arange(a)\n",
    "width = 0.35 # the width of the bars\n",
    "mean = ax.bar(ind+width, MEAN, width, color='green',yerr=Sd, label='Mean Square Error')\n",
    "measurements=ax.plot(ind+0.9*width,Errors,'ro',color='blue', label='Last error')\n",
    "ax.set_xticks(ind+1.5*width)\n",
    "ax.set_xticklabels(('FeedForward',  'Recurrent', 'Recurrent 2'))\n",
    "\n",
    "blue_line = mlines.Line2D([], [], color='blue', marker='|',\n",
    "                          markersize=8, label='Standar Deviation')\n",
    "blue_point = mlines.Line2D([], [], color='blue', marker='o',\n",
    "                          markersize=8, label='Last training error')\n",
    "plt.legend(handles=[mean,blue_line,blue_point])\n",
    "\n",
    "ax.set_ylabel('Mean Square Error')\n",
    "ax.set_title('Descriptive Error Bars for 20 trainings',size='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
