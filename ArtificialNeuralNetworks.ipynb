{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pybrain\n",
    "from pybrain.structure import RecurrentNetwork, FeedForwardNetwork, LinearLayer, SigmoidLayer, FullConnection\n",
    "from IPython.display import Image\n",
    "from pybrain.structure import connections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline --no-import-all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three networks are compared: \n",
    "* A FeedForward network \"One-step-ahead prediction\": **netF**\n",
    ">The networks has 24 inputs, which means 8 for each step (t, t-1, t-2)\n",
    ">A Backpropagation trainer is used. \n",
    "* A RecurrentNetwork looking 1 step in the past: **netR** \n",
    ">This network is a RecurrentNetwork. The trainer is a BackPropTrainer without any configuration, just in the way PyBrain makes it work. It is a Backpropagation through time with one step backward \n",
    "* A RecurrentNetwork looking 2 steps in the past: **netR2**\n",
    ">This is also a RecurrentNetwork trained with Backpropagation through time but changed to two steps backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netF = FeedForwardNetwork()\n",
    "netR = RecurrentNetwork()\n",
    "netR2 = RecurrentNetwork()\n",
    "    \n",
    "    \n",
    "inpF = LinearLayer(24)\n",
    "hidF = SigmoidLayer(24)\n",
    "outF = LinearLayer(2)\n",
    "\n",
    "inpR = LinearLayer(8, name='in')\n",
    "hidR = SigmoidLayer(8, name='hidden')\n",
    "outR = LinearLayer(2, name='out')\n",
    "\n",
    "inpR2 = LinearLayer(8, name='in2')\n",
    "hidR2 = SigmoidLayer(8, name='hidden2')\n",
    "outR2 = LinearLayer(2, name='out2')\n",
    "    \n",
    "netF.addInputModule(inpF)\n",
    "netF.addModule(hidF)\n",
    "netF.addOutputModule(outF)\n",
    "\n",
    "\n",
    "netR.addInputModule(inpR)\n",
    "netR.addModule(hidR)\n",
    "netR.addOutputModule(outR)\n",
    "\n",
    "netR2.addInputModule(inpR2)\n",
    "netR2.addModule(hidR2)\n",
    "netR2.addOutputModule(outR2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feedforward connections\n",
    "\n",
    "netF.addConnection(FullConnection(inpF,hidF))\n",
    "netF.addConnection(FullConnection(hidF,outF))\n",
    "netF.sortModules()\n",
    "\n",
    "netR.addConnection(FullConnection(netR['in'],netR['hidden'], name='c1'))\n",
    "netR.addConnection(FullConnection(netR['hidden'],netR['out'], name='c2'))\n",
    "netR.sortModules()\n",
    "\n",
    "netR2.addConnection(FullConnection(netR2['in2'],netR2['hidden2'], name='c3'))\n",
    "netR2.addConnection(FullConnection(netR2['hidden2'],netR2['out2'], name='c4'))\n",
    "netR2.sortModules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Recurrent connections\n",
    "\n",
    "netR.addRecurrentConnection(FullConnection(netR['in'],netR['in'], name='cR1'))\n",
    "netR.addRecurrentConnection(FullConnection(netR['hidden'],netR['hidden'], name='cR2'))\n",
    "netR.addRecurrentConnection(FullConnection(netR['out'],netR['out'], name='cR3'))\n",
    "netR.sortModules()\n",
    "\n",
    "netR2.addRecurrentConnection(FullConnection(netR2['in2'],netR2['in2'], name='cR4'))\n",
    "netR2.addRecurrentConnection(FullConnection(netR2['hidden2'],netR2['hidden2'], name='cR5'))\n",
    "netR2.addRecurrentConnection(FullConnection(netR2['out2'],netR2['out2'], name='cR6'))\n",
    "netR2.sortModules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.datasets import SupervisedDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to get the data from a CSV file is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getcsv( filename ):\n",
    "    temp = np.fromfile( filename, sep=';' )\n",
    "    numcols = len( temp )\n",
    "    del( temp )\n",
    "    df = pd.read_csv( filename, sep=';', names = [ x+1 for x in range(numcols)] )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three files needed: \n",
    "* The training data\n",
    "* The validation data\n",
    "* The test data\n",
    "    - Collector Greenhouse\n",
    "    - Reference Greenhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=getcsv('train.csv')\n",
    "val = getcsv( 'val.csv' )\n",
    "test_ref=getcsv('testref.csv')\n",
    "test_col=getcsv('testcol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = [ \\\n",
    "    'Record(1)', 'Temperature(1)', 'RelHum(1)', \\\n",
    "    'Ventilation(1)', 'Screening(1)', 'Heating(1)', 'Cooling(1)', \\\n",
    "    'LAI(1)', 'OutTemp(1)', 'OutRelHum(1)', 'OutRad(1)', 'OutWindVel(1)', \\\n",
    "    'HourAngle(1)', 'Declination(1)', 'Elevation(1)', 'RadTheor(1)', \\\n",
    "    'Record(0)', 'Temperature(0)', 'RelHum(0)', \\\n",
    "    'Ventilation(0)', 'Screening(0)', 'Heating(0)', 'Cooling(0)', \\\n",
    "    'LAI(0)', 'OutTemp(0)', 'OutRelHum(0)', 'OutRad(0)', 'OutWindVel(0)', \\\n",
    "    'HourAngle(0)', 'Declination(0)', 'Elevation(0)', 'RadTheor(0)', \\\n",
    "    'Record(-1)', 'Temperature(-1)', 'RelHum(-1)', \\\n",
    "    'Ventilation(-1)', 'Screening(-1)', 'Heating(-1)', 'Cooling(-1)', \\\n",
    "    'LAI(-1)', 'OutTemp(-1)', 'OutRelHum(-1)', 'OutRad(-1)', 'OutWindVel(-1)', \\\n",
    "    'HourAngle(-1)', 'Declination(-1)', 'Elevation(-1)', 'RadTheor(-1)', \\\n",
    "    'Record(-2)', 'Temperature(-2)', 'RelHum(-2)', \\\n",
    "    'Ventilation(-2)', 'Screening(-2)', 'Heating(-2)', 'Cooling(-2)', \\\n",
    "    'LAI(-2)', 'OutTemp(-2)', 'OutRelHum(-2)', 'OutRad(-2)', 'OutWindVel(-2)', \\\n",
    "    'HourAngle(-2)', 'Declination(-2)', 'Elevation(-2)', 'RadTheor(-2)', \\\n",
    "    'Record(-3)', 'Temperature(-3)', 'RelHum(-3)', \\\n",
    "    'Ventilation(-3)', 'Screening(-3)', 'Heating(-3)', 'Cooling(-3)', \\\n",
    "    'LAI(-3)', 'OutTemp(-3)', 'OutRelHum(-3)', 'OutRad(-3)', 'OutWindVel(-3)', \\\n",
    "    'HourAngle(-3)', 'Declination(-3)', 'Elevation(-3)', 'RadTheor(-3)', \\\n",
    "    ]\n",
    "train.columns = cols\n",
    "val.columns = cols\n",
    "test_ref.columns=cols\n",
    "test_col.columns=cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to enhance the comparison and the error calculation process, the data are normalized. This makes posible to have a common format doesn't matter the units. \n",
    "The functions to normalize and de-normalize the data are shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max & min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexm=([\"maximos\",\"minimos\"])\n",
    "mm = pd.DataFrame(columns=train.columns,index=indexm)\n",
    "\n",
    "for n in range(1,train.shape[1]):\n",
    "    max1=max(train[train.columns[n]])\n",
    "    max2=max(val[val.columns[n]])\n",
    "    mm[mm.columns[n]][\"maximos\"]=max(max1,max2)\n",
    "    \n",
    "    min1=min(train[train.columns[n]])\n",
    "    min2=min(val[val.columns[n]])\n",
    "    mm[mm.columns[n]][\"minimos\"]=min(min1,min2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def norm(x,maxi,mini):\n",
    "    Vnorm=(2*((x-mini)/(maxi-mini)))-1\n",
    "    return Vnorm  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def a_norm(y,maxi,mini):\n",
    "    Anorm=(((y+1)*(maxi-mini))/2)+mini\n",
    "    return Anorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ntrain = pd.DataFrame(columns=train.columns)\n",
    "Nval = pd.DataFrame(columns=val.columns)\n",
    "Ntest_col = pd.DataFrame(columns=test_col.columns)\n",
    "Ntest_ref = pd.DataFrame(columns=test_ref.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(1,train.shape[1]):\n",
    "    ar=train[train.columns[n]]\n",
    "    Ntrain[Ntrain.columns[n]]=norm(ar,mm[mm.columns[n]][\"maximos\"],mm[mm.columns[n]][\"minimos\"])\n",
    "    \n",
    "for n in range(1,val.shape[1]):\n",
    "    ar=val[val.columns[n]]\n",
    "    Nval[Nval.columns[n]]=norm(ar,mm[mm.columns[n]][\"maximos\"],mm[mm.columns[n]][\"minimos\"])\n",
    "    \n",
    "for n in range(1,test_col.shape[1]):\n",
    "    ar=test_col[test_col.columns[n]]\n",
    "    Ntest_col[Ntest_col.columns[n]]=norm(ar,mm[mm.columns[n]][\"maximos\"],mm[mm.columns[n]][\"minimos\"])\n",
    "\n",
    "for n in range(1,test_ref.shape[1]):\n",
    "    ar=test_ref[test_ref.columns[n]]\n",
    "    Ntest_ref[Ntest_ref.columns[n]]=norm(ar,mm[mm.columns[n]][\"maximos\"],mm[mm.columns[n]][\"minimos\"])\n",
    "    \n",
    "\n",
    "##The first column with the record number remains the same     \n",
    "Ntrain[Ntrain.columns[0]]=train[train.columns[0]]\n",
    "Nval[Nval.columns[0]]=val[val.columns[0]]\n",
    "Ntest_col[Ntest_col.columns[0]]=test_col[test_col.columns[0]]\n",
    "Ntest_ref[Ntest_ref.columns[0]]=test_ref[test_ref.columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, the data is going from -1 to 1, doesn't matter the units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ntest_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the datasets for training and validation are created with the standarized data from the files.\n",
    ">There are training and validation datasets for the FeedForward network and training and validation datasets for the Recurrent Networks\n",
    ">This is due to the different number of inputs for each different typology of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#________________________________________________Training_______________________________________________________\n",
    "\n",
    "s=np.array([Ntrain['Temperature(-2)'],Ntrain['RelHum(-2)'],Ntrain['Ventilation(-2)'],Ntrain['Screening(-2)'], \\\n",
    "           Ntrain['HourAngle(-2)'],Ntrain['Declination(-2)'],Ntrain['Elevation(-2)'],Ntrain['RadTheor(-2)'], \\\n",
    "           Ntrain['Temperature(-1)'],Ntrain['RelHum(-1)'],Ntrain['Ventilation(-1)'],Ntrain['Screening(-1)'], \\\n",
    "           Ntrain['HourAngle(-1)'],Ntrain['Declination(-1)'],Ntrain['Elevation(-1)'],Ntrain['RadTheor(-1)'], \\\n",
    "           Ntrain['Temperature(0)'],Ntrain['RelHum(0)'],Ntrain['Ventilation(0)'],Ntrain['Screening(0)'], \\\n",
    "           Ntrain['HourAngle(0)'],Ntrain['Declination(0)'],Ntrain['Elevation(0)'],Ntrain['RadTheor(0)']]).T\n",
    "\n",
    "t=np.array([Ntrain['Temperature(1)'],Ntrain['RelHum(1)']]).T\n",
    "\n",
    "\n",
    "#______________________________________________Validation_______________________________________________________\n",
    "\n",
    "sval=np.array([Nval['Temperature(-2)'],Nval['RelHum(-2)'],Nval['Ventilation(-2)'],Nval['Screening(-2)'], \\\n",
    "           Nval['HourAngle(-2)'],Nval['Declination(-2)'],Nval['Elevation(-2)'],Nval['RadTheor(-2)'], \\\n",
    "           Nval['Temperature(-1)'],Nval['RelHum(-1)'],Nval['Ventilation(-1)'],Nval['Screening(-1)'], \\\n",
    "           Nval['HourAngle(-1)'],Nval['Declination(-1)'],Nval['Elevation(-1)'],Nval['RadTheor(-1)'], \\\n",
    "           Nval['Temperature(0)'],Nval['RelHum(0)'],Nval['Ventilation(0)'],Nval['Screening(0)'], \\\n",
    "           Nval['HourAngle(0)'],Nval['Declination(0)'],Nval['Elevation(0)'],Nval['RadTheor(0)']]).T\n",
    "\n",
    "tval=np.array([Nval['Temperature(1)'],Nval['RelHum(1)']]).T     \n",
    "\n",
    "\n",
    "#________________________________________________Test____________________________________________________________\n",
    "\n",
    "stest_col=np.array([Ntest_col['Temperature(-2)'],Ntest_col['RelHum(-2)'],Ntest_col['Ventilation(-2)'],Ntest_col['Screening(-2)'], \\\n",
    "           Ntest_col['HourAngle(-2)'],Ntest_col['Declination(-2)'],Ntest_col['Elevation(-2)'],Ntest_col['RadTheor(-2)'], \\\n",
    "           Ntest_col['Temperature(-1)'],Ntest_col['RelHum(-1)'],Ntest_col['Ventilation(-1)'],Ntest_col['Screening(-1)'], \\\n",
    "           Ntest_col['HourAngle(-1)'],Ntest_col['Declination(-1)'],Ntest_col['Elevation(-1)'],Ntest_col['RadTheor(-1)'], \\\n",
    "           Ntest_col['Temperature(0)'],Ntest_col['RelHum(0)'],Ntest_col['Ventilation(0)'],Ntest_col['Screening(0)'], \\\n",
    "           Ntest_col['HourAngle(0)'],Ntest_col['Declination(0)'],Ntest_col['Elevation(0)'],Ntest_col['RadTheor(0)']]).T\n",
    "\n",
    "ttest_col=np.array([Ntest_col['Temperature(1)'],Ntest_col['RelHum(1)']]).T     \n",
    "\n",
    "\n",
    "stest_ref=np.array([Ntest_ref['Temperature(-2)'],Ntest_ref['RelHum(-2)'],Ntest_ref['Ventilation(-2)'],Ntest_ref['Screening(-2)'], \\\n",
    "           Ntest_ref['HourAngle(-2)'],Ntest_ref['Declination(-2)'],Ntest_ref['Elevation(-2)'],Ntest_ref['RadTheor(-2)'], \\\n",
    "           Ntest_ref['Temperature(-1)'],Ntest_ref['RelHum(-1)'],Ntest_ref['Ventilation(-1)'],Ntest_ref['Screening(-1)'], \\\n",
    "           Ntest_ref['HourAngle(-1)'],Ntest_ref['Declination(-1)'],Ntest_ref['Elevation(-1)'],Ntest_ref['RadTheor(-1)'], \\\n",
    "           Ntest_ref['Temperature(0)'],Ntest_ref['RelHum(0)'],Ntest_ref['Ventilation(0)'],Ntest_ref['Screening(0)'], \\\n",
    "           Ntest_ref['HourAngle(0)'],Ntest_ref['Declination(0)'],Ntest_ref['Elevation(0)'],Ntest_ref['RadTheor(0)']]).T\n",
    "\n",
    "ttest_ref=np.array([Ntest_ref['Temperature(1)'],Ntest_ref['RelHum(1)']]).T     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#__________________________________________Training______________________________________________________________\n",
    "\n",
    "sR=np.array([Ntrain['Temperature(0)'],Ntrain['RelHum(0)'],Ntrain['Ventilation(0)'],Ntrain['Screening(0)'], \\\n",
    "           Ntrain['HourAngle(0)'],Ntrain['Declination(0)'],Ntrain['Elevation(0)'],Ntrain['RadTheor(0)']]).T\n",
    "\n",
    "tR=np.array([Ntrain['Temperature(1)'],Ntrain['RelHum(1)']]).T\n",
    "\n",
    "\n",
    "#__________________________________________Validation_____________________________________________________________\n",
    "\n",
    "svalR=np.array([Nval['Temperature(0)'],Nval['RelHum(0)'],Nval['Ventilation(0)'],Nval['Screening(0)'], \\\n",
    "           Nval['HourAngle(0)'],Nval['Declination(0)'],Nval['Elevation(0)'],Nval['RadTheor(0)']]).T\n",
    "\n",
    "tvalR=np.array([Nval['Temperature(1)'],Nval['RelHum(1)']]).T     \n",
    "\n",
    "\n",
    "#____________________________________________Test__________________________________________________________________\n",
    "\n",
    "stest_colR=np.array([Ntest_col['Temperature(0)'],Ntest_col['RelHum(0)'],Ntest_col['Ventilation(0)'],Ntest_col['Screening(0)'], \\\n",
    "           Ntest_col['HourAngle(0)'],Ntest_col['Declination(0)'],Ntest_col['Elevation(0)'],Ntest_col['RadTheor(0)']]).T\n",
    "\n",
    "ttest_colR=np.array([Ntest_col['Temperature(1)'],Ntest_col['RelHum(1)']]).T  \n",
    "\n",
    "\n",
    "stest_refR=np.array([Ntest_ref['Temperature(0)'],Ntest_ref['RelHum(0)'],Ntest_ref['Ventilation(0)'],Ntest_ref['Screening(0)'], \\\n",
    "           Ntest_ref['HourAngle(0)'],Ntest_ref['Declination(0)'],Ntest_ref['Elevation(0)'],Ntest_ref['RadTheor(0)']]).T\n",
    "\n",
    "ttest_refR=np.array([Ntest_ref['Temperature(1)'],Ntest_ref['RelHum(1)']]).T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Length of the data\n",
    "\n",
    "data_length=len(s)\n",
    "length_Val=len(sval)\n",
    "length_Test=len(stest_col)\n",
    "print('Ttraining:',data_length,'\\nValidation:',length_Val,'\\nTest:',length_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataset for training\n",
    "\n",
    "dataF = SupervisedDataSet(24,2)\n",
    "dataR = SupervisedDataSet(8,2)\n",
    "\n",
    "for m in range(0,data_length):\n",
    "    dataF.addSample(s[m],t[m])  \n",
    "    dataR.addSample(sR[m],tR[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.supervised import BackpropTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two functions are defined below for the RMSE and MSE calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def mse(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeedForward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is trained with BackpropTrainer for 1000 epochs. Inside the training loop, three errors are calculated:\n",
    "* The one given by the trainer **errors1**\n",
    "* The MSE calculated with the same training data **errors2**\n",
    "* The validation MSE **errorsVal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = BackpropTrainer(netF, dataF, learningrate = 0.001, momentum = 0.99, verbose=False)\n",
    "\n",
    "errors1 = np.array([])\n",
    "errors2=np.array([])\n",
    "errorsVal=np.array([])\n",
    "\n",
    "#_______________________________________Trainer error_________________________________________________\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    temp = trainer.train()\n",
    "    errors1=np.append(errors1,temp)\n",
    "    \n",
    "#______________________________________calculated MSE________________________________________________\n",
    "\n",
    "    er2=np.array([])\n",
    "    for inps in s:\n",
    "        j=netF.activate(inps)\n",
    "        er2=np.append(er2,j)\n",
    "    er2=np.reshape(er2,[data_length,2])\n",
    "    errors2=np.append(errors2,mse(er2,t))\n",
    "    \n",
    "\n",
    "#_______________________________________validation MSE_______________________________________________\n",
    "    \n",
    "    er_Val=np.array([])\n",
    "    for inps in sval:\n",
    "        k=netF.activate(inps)\n",
    "        er_Val=np.append(er_Val,k)\n",
    "    er_Val=np.reshape(er_Val,[length_Val,2])\n",
    "    errorsVal=np.append(errorsVal,mse(er_Val,tval))\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given and the calculated training errors are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('   errors1','     errors2', 'Difference e1/e2')\n",
    "for i in range(0,epochs):\n",
    "    print(i, errors1[i],'->',errors2[i],'    ', errors1[i]/errors2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure demonstrates the difference between both MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax1.plot(errors1,color='blue', linewidth=1.0, label='Errors1')\n",
    "#ax1.plot(errors2,color='red', marker='.', linestyle=' ',linewidth=1.0, label='Errors2')\n",
    "ax1.plot(errors2,color='red',linewidth=1.0, label='Errors2')\n",
    "ax1.set_title('Given and Calculated Errors for Feedforward Network');\n",
    "#ax.set_xlim([0,20])\n",
    "#ax.set_ylim([0,30])\n",
    "ax1.legend(loc='upper right')\n",
    "fig1.savefig(\"figure1.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Network offset=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the FeedForward network, this network is trained with BackpropTrainer through time for 1000 epochs and one step backwards. Inside the training loop, three errors are calculated:\n",
    "* The one given by the trainer **errors1_R**\n",
    "* The MSE calculated with the same training data **errors2_R**\n",
    "* The validation MSE **errorsVal_R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainerR = BackpropTrainer(netR, dataR, learningrate = 0.001, momentum = 0.99, verbose = False)\n",
    "\n",
    "errors1_R = np.array([])\n",
    "errors2_R=np.array([])\n",
    "errorsVal_R=np.array([])\n",
    "\n",
    "#_______________________________________Trainer error_________________________________________________\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    temp = trainerR.train()\n",
    "    errors1_R=np.append(errors1_R,temp)\n",
    "    \n",
    "#______________________________________calculated MSE________________________________________________\n",
    "\n",
    "    er2_R=np.array([])\n",
    "    for inps_R in sR:\n",
    "        netR.reset()\n",
    "        j_R=netR.activate(inps_R)\n",
    "        er2_R=np.append(er2_R,j_R)\n",
    "    er2_R=np.reshape(er2_R,[data_length,2])\n",
    "    errors2_R=np.append(errors2_R,mse(er2_R,tR))\n",
    "    \n",
    "#_______________________________________validation MSE_______________________________________________\n",
    "    \n",
    "    er_Val_R=np.array([])\n",
    "    for inps in svalR:\n",
    "        netR.reset()\n",
    "        k_R=netR.activate(inps)\n",
    "        er_Val_R=np.append(er_Val_R,k_R)\n",
    "    er_Val_R=np.reshape(er_Val_R,[length_Val,2])\n",
    "    errorsVal_R=np.append(errorsVal_R,mse(er_Val_R,tvalR))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given and the calculated training errors are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('   errors1_R','     errors2_R', 'Difference e1/e2')\n",
    "for i in range(0,epochs):\n",
    "    print(i,errors1_R[i],'->',errors2_R[i],'    ', errors1_R[i]/errors2_R[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure demonstrates the difference between both MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax2.plot(errors1_R,color='blue', linewidth=1.0, label='Errors1_R')\n",
    "ax2.plot(errors2_R,color='red', linewidth=1.0, label='Errors2_R')\n",
    "ax2.set_title('Given and Calculated Errors for the Recurrent Network 1');\n",
    "#ax.set_xlim([0,20])\n",
    "#ax2.set_ylim([0,0.05])\n",
    "ax2.legend(loc='upper right')\n",
    "fig2.savefig(\"figure2.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Network offset=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value for the offset is 1. In order to make the network look two steps in the past is necesary to change this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netR2.maxoffset=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the two networks shown above, this network is trained with BackpropTrainer through time for 1000 epochs but with two step backwards. Inside the training loop, three errors are calculated:\n",
    "* The one given by the trainer **errors1_R2**\n",
    "* The MSE calculated with the same training data **errors2_R2**\n",
    "* The validation MSE **errorsVal_R2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainerR2 = BackpropTrainer(netR2, dataR, learningrate = 0.001, momentum = 0.99, verbose = False)\n",
    "\n",
    "\n",
    "errors1_R2 = np.array([])\n",
    "errors2_R2=np.array([])\n",
    "errorsVal_R2=np.array([])\n",
    "\n",
    "#_______________________________________Trainer error_________________________________________________\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    temp = trainerR2.train()\n",
    "    errors1_R2=np.append(errors1_R2,temp)\n",
    "    \n",
    "#______________________________________calculated MSE________________________________________________\n",
    "\n",
    "    er2_R2=np.array([])\n",
    "    for inpsR2 in sR:\n",
    "        netR2.reset()\n",
    "        j_R2=netR2.activate(inpsR2)\n",
    "        er2_R2=np.append(er2_R2,j_R2)\n",
    "    er2_R2=np.reshape(er2_R2,[data_length,2])\n",
    "    errors2_R2=np.append(errors2_R2,mse(er2_R2,tR))\n",
    "    \n",
    "#_______________________________________validation MSE_______________________________________________\n",
    "    \n",
    "    er_Val_R2=np.array([])\n",
    "    for inps in svalR:\n",
    "        netR2.reset()\n",
    "        k_R2=netR2.activate(inps)\n",
    "        er_Val_R2=np.append(er_Val_R2,k_R2)\n",
    "    er_Val_R2=np.reshape(er_Val_R2,[length_Val,2])\n",
    "    errorsVal_R2=np.append(errorsVal_R2,mse(er_Val_R2,tvalR))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The given and the calculated training errors are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('   errors1_R2','     errors2_R2', 'Difference e1/e2')\n",
    "for i in range(0,epochs):\n",
    "    print(i,errors1_R2[i],'->',errors2_R2[i],'    ', errors1_R2[i]/errors2_R2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure demonstrates the difference between both MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax3.plot(errors1_R2,color='blue', linewidth=1.0, label='Errors1_R2')\n",
    "ax3.plot(errors2_R2,color='red', linewidth=1.0, label='Errors2_R2')\n",
    "ax3.set_title('Given and Calculated Errors for the Recurrent Network 2');\n",
    "#ax3.set_xlim([20,40])\n",
    "#ax3.set_ylim([0,.030])\n",
    "ax3.legend(loc='upper right')\n",
    "fig3.savefig(\"figure3.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision between the three tipologies of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure below it is shown the MSE calculated for each Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax4.plot(errors2,color='blue', linewidth=1.0, label='FeedForward')\n",
    "ax4.plot(errors2_R,color='magenta', linewidth=1.0, label='RecurrentNetwork')\n",
    "ax4.plot(errors2_R2,color='green', linewidth=1.0,label='RecurrentNetwork 2')\n",
    "ax4.set_title('MSE ');\n",
    "#ax4.set_xlim([900,1000])\n",
    "#ax4.set_ylim([0,0.002])\n",
    "ax4.legend(loc='upper right')\n",
    "fig4.savefig(\"figure4.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validation graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feedforward Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax5.plot(errors2,color='red', linewidth=1.0, label='Training Error')\n",
    "ax5.plot(errorsVal,color='magenta', linewidth=1.0,label='Validation Error')\n",
    "ax5.set_title('Training vs Validation Error: FeedForward');\n",
    "#ax5.set_xlim([90,100])\n",
    "#ax5.set_ylim([0,.1])\n",
    "ax5.legend(loc='upper right')\n",
    "fig5.savefig(\"figure5.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recurrent Network offset=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig6, ax6 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax6.plot(errors2_R,color='red', linewidth=1.0,label='Training Error')\n",
    "ax6.plot(errorsVal_R,color='magenta', linewidth=1.0,label='Validation Error')\n",
    "ax6.set_title('Training vs Validation Error: RecurrentNetwork 1');\n",
    "#ax6.set_xlim([0,200])\n",
    "#ax6.set_ylim([0,100])\n",
    "ax6.legend(loc='upper right')\n",
    "fig6.savefig(\"figure6.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recurrent Network offset=2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig7, ax7 = plt.subplots(1, sharex=True, figsize=(35,8))\n",
    "ax7.plot(errors2_R2,color='red', linewidth=1.0,label='Training Error')\n",
    "ax7.plot(errorsVal_R2,color='magenta', linewidth=1.0,label='Validation Error')\n",
    "ax7.set_title('Training vs Validation Error: RecurrentNetwork 2');\n",
    "#ax7.set_xlim([0,200])\n",
    "#ax7.set_ylim([0,100])\n",
    "ax7.legend(loc='upper right')\n",
    "fig7.savefig(\"figure7.pdf\") # save as pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_______________________________Collector Greenhouse__________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_col):\n",
    "    netF.reset()\n",
    "    j=np.append(j,netF.activate( inps ))\n",
    "\n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTest_col=mse(j,ttest_col)\n",
    "\n",
    "temperature_errorTest_col=mse(j[0],ttest_col[0])\n",
    "humidity_errorTest_col=mse(j[1],ttest_col[1])\n",
    "\n",
    "\n",
    "#______________________________Reference Greenhouse___________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_ref):\n",
    "    netF.reset()\n",
    "    j=np.append(j,netF.activate( inps ))\n",
    "    \n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTest_ref=mse(j,ttest_ref)\n",
    "\n",
    "temperature_errorTest_ref=mse(j[0],ttest_ref[0])\n",
    "humidity_errorTest_ref=mse(j[1],ttest_ref[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Network, offset=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#_______________________________Collector Greenhouse__________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_colR):\n",
    "    netR.reset()\n",
    "    j=np.append(j,netR.activate( inps ))\n",
    "\n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTestR_col=mse(j,ttest_colR)\n",
    "\n",
    "temperature_errorTestR_col=mse(j[0],ttest_colR[0])\n",
    "humidity_errorTestR_col=mse(j[1],ttest_colR[1])\n",
    "\n",
    "#______________________________Reference Greenhouse___________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_refR):\n",
    "    netR.reset()\n",
    "    j=np.append(j,netR.activate( inps ))\n",
    "    \n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTestR_ref=mse(j,ttest_refR)\n",
    "\n",
    "temperature_errorTestR_ref=mse(j[0],ttest_refR[0])\n",
    "humidity_errorTestR_ref=mse(j[1],ttest_refR[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Network, offset=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#_______________________________Collector Greenhouse__________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_colR):\n",
    "    netR2.reset()\n",
    "    j=np.append(j,netR2.activate( inps ))\n",
    "\n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTestR2_col=mse(j,ttest_colR)\n",
    "\n",
    "temperature_errorTestR2_col=mse(j[0],ttest_colR[0])\n",
    "humidity_errorTestR2_col=mse(j[1],ttest_colR[1])\n",
    "\n",
    "#______________________________Reference Greenhouse___________________________\n",
    "\n",
    "j=np.array([])\n",
    "for inps in (stest_refR):\n",
    "    netR2.reset()\n",
    "    j=np.append(j,netR2.activate( inps ))  \n",
    "j=np.reshape(j,[length_Test,2])    \n",
    "\n",
    "errorTestR2_ref=mse(j,ttest_refR)\n",
    "\n",
    "temperature_errorTestR2_ref=mse(j[0],ttest_refR[0])\n",
    "humidity_errorTestR2_ref=mse(j[1],ttest_refR[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the three Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig8, ax8 = plt.subplots(1, sharex=True, figsize=(10,7))\n",
    "a=3\n",
    "\n",
    "collector=[errorTest_col,errorTestR_col,errorTestR2_col]\n",
    "reference=[errorTest_ref,errorTestR_ref,errorTestR2_ref]\n",
    "\n",
    "ind = np.arange(a)  # the x locations for the groups\n",
    "width = 0.15 # the width of the bars\n",
    "\n",
    "rects1 = ax8.bar(0.5*ind, collector, width, color='green')\n",
    "rects2 = ax8.bar(0.5*ind+width, reference, width, color='blue')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax8.set_title('MSE for the three typologies of Neural Networks')\n",
    "ax8.set_ylabel('MSE')\n",
    "ax8.set_xticks(0.5*ind +width)\n",
    "ax8.set_xticklabels(('FeedForward',  'Recurrent', 'Recurrent 2'))\n",
    "ax8.set_ylim([0,0.25])\n",
    "ax8.legend(('Collector', 'Reference'),loc='upper right',)\n",
    "fig8.savefig(\"figure8.pdf\") # save as pdf\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig9, ax9 = plt.subplots(1, sharex=True, figsize=(7,5))\n",
    "\n",
    "a=2\n",
    "collector=[temperature_errorTest_col,humidity_errorTest_col]\n",
    "reference=[temperature_errorTest_ref,humidity_errorTest_ref]\n",
    "\n",
    "ind = np.arange(a)  # the x locations for the groups\n",
    "width = 0.15 # the width of the bars\n",
    "\n",
    "\n",
    "rects1 = ax9.bar(0.5*ind, collector, width, color='orange')\n",
    "rects2 = ax9.bar(0.5*ind+width, reference, width, color='yellow')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax9.set_title('MSE for the Feedforward Neural Network')\n",
    "ax9.set_ylabel('MSE')\n",
    "ax9.set_xticks(0.5*ind +width)\n",
    "ax9.set_xticklabels(('Temperature',  'Humidity'))\n",
    "ax9.set_ylim([0,0.01])\n",
    "ax9.legend(('Collector', 'Reference'),loc='upper right',)\n",
    "fig9.savefig(\"figure9.pdf\") # save as pdf\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Network, offset=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig10, ax10 = plt.subplots(1, sharex=True, figsize=(7,5))\n",
    "\n",
    "a=2\n",
    "collector=[temperature_errorTestR_col,humidity_errorTestR_col]\n",
    "reference=[temperature_errorTestR_ref,humidity_errorTestR_ref]\n",
    "\n",
    "ind = np.arange(a)  # the x locations for the groups\n",
    "width = 0.15 # the width of the bars\n",
    "\n",
    "\n",
    "rects1 = ax10.bar(0.5*ind, collector, width, color='orange')\n",
    "rects2 = ax10.bar(0.5*ind+width, reference, width, color='yellow')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax10.set_title('MSE for the Recurrent Neural Network, offset=1')\n",
    "ax10.set_ylabel('MSE')\n",
    "ax10.set_xticks(0.5*ind +width)\n",
    "ax10.set_xticklabels(('Temperature',  'Humidity'))\n",
    "ax10.set_ylim([0,0.1])\n",
    "ax10.legend(('Collector', 'Reference'),loc='upper right',)\n",
    "fig10.savefig(\"figure10.pdf\") # save as pdf\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Network, offset=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig11, ax11 = plt.subplots(1, sharex=True, figsize=(7,5))\n",
    "\n",
    "a=2\n",
    "collector=[temperature_errorTestR2_col,humidity_errorTestR2_col]\n",
    "reference=[temperature_errorTestR2_ref,humidity_errorTestR2_ref]\n",
    "\n",
    "ind = np.arange(a)  # the x locations for the groups\n",
    "width = 0.15 # the width of the bars\n",
    "\n",
    "\n",
    "rects1 = ax11.bar(0.5*ind, collector, width, color='orange')\n",
    "rects2 = ax11.bar(0.5*ind+width, reference, width, color='yellow')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax11.set_title('MSE for the Recurrent Neural Network, offset=2')\n",
    "ax11.set_ylabel('MSE')\n",
    "ax11.set_xticks(0.5*ind +width)\n",
    "ax11.set_xticklabels(('Temperature',  'Humidity'))\n",
    "ax11.set_ylim([0,0.1])\n",
    "ax11.legend(('Collector', 'Reference'),loc='upper right',)\n",
    "fig11.savefig(\"figure11.pdf\") # save as pdf\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
